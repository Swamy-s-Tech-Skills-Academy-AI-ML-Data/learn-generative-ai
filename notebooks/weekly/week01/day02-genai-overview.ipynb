{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbef9841",
   "metadata": {},
   "source": [
    "# Day 2: How GenAI Works (Overview) - Interactive Practice\n",
    "\n",
    "**Learning Objective**: Understand the two-phase process of generative AI: training vs generation.\n",
    "\n",
    "**Time**: 15 minutes of hands-on practice\n",
    "\n",
    "**Prerequisites**: Read [Day 2 Guide](../../../docs/daily-guides/week01/day02-genai-overview.md) first (10 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bff67f",
   "metadata": {},
   "source": [
    "## 🎯 Today's Focus: Training vs Generation Phases\n",
    "\n",
    "Let's explore how GenAI works through the two distinct phases with interactive simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e96e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import libraries for our two-phase exploration\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "print(\"🚀 Day 2 Environment Ready!\")\n",
    "print(\"Today we'll explore: Training Phase vs Generation Phase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69bba6",
   "metadata": {},
   "source": [
    "## 📚 Phase 1: Training Simulation\n",
    "\n",
    "Let's simulate how AI learns patterns during training by analyzing text patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d3eac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_phase_simulation(training_texts: List[str]) -> Dict[str, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Simulates the training phase: learning patterns from data.\n",
    "    This is when the AI builds its internal knowledge.\n",
    "    \"\"\"\n",
    "    print(\"🔄 TRAINING PHASE: Learning patterns from data...\")\n",
    "\n",
    "    # Simple pattern learning: word sequences (bigrams)\n",
    "    word_patterns = defaultdict(Counter)\n",
    "\n",
    "    for text in training_texts:\n",
    "        words = text.lower().split()\n",
    "        # Learn what word typically follows each word\n",
    "        for i in range(len(words) - 1):\n",
    "            current_word = words[i]\n",
    "            next_word = words[i + 1]\n",
    "            word_patterns[current_word][next_word] += 1\n",
    "\n",
    "    print(f\"   📊 Processed {len(training_texts)} training examples\")\n",
    "    print(f\"   🧠 Learned patterns for {len(word_patterns)} words\")\n",
    "\n",
    "    return dict(word_patterns)\n",
    "\n",
    "\n",
    "# Training data examples\n",
    "training_data = [\n",
    "    \"the cat sat on the mat\",\n",
    "    \"the dog ran in the park\",\n",
    "    \"the cat played with the ball\",\n",
    "    \"the dog sat in the sun\",\n",
    "    \"the cat ran to the tree\",\n",
    "    \"the dog played in the yard\"\n",
    "]\n",
    "\n",
    "# Execute training phase\n",
    "learned_patterns = training_phase_simulation(training_data)\n",
    "\n",
    "# Show what the AI learned\n",
    "print(\"\\n🧠 Patterns Learned During Training:\")\n",
    "for word, next_words in list(learned_patterns.items())[:3]:  # Show first 3\n",
    "    print(f\"   After '{word}', often comes: {dict(next_words)}\")\n",
    "\n",
    "print(\"\\n💡 Key insight: Training builds internal pattern knowledge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b1bbb3",
   "metadata": {},
   "source": [
    "## ✨ Phase 2: Generation Simulation\n",
    "\n",
    "Now let's simulate how AI uses learned patterns to generate new content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_phase_simulation(learned_patterns: Dict, start_word: str, max_length: int = 6) -> str:\n",
    "    \"\"\"\n",
    "    Simulates the generation phase: using learned patterns to create new text.\n",
    "    This is when the AI produces new content.\n",
    "    \"\"\"\n",
    "    print(\n",
    "        f\"✨ GENERATION PHASE: Creating new text starting with '{start_word}'...\")\n",
    "\n",
    "    generated_words = [start_word]\n",
    "    current_word = start_word\n",
    "\n",
    "    for step in range(max_length - 1):\n",
    "        if current_word in learned_patterns:\n",
    "            # Choose next word based on learned patterns\n",
    "            possible_next_words = learned_patterns[current_word]\n",
    "            # Weighted random choice based on training frequency\n",
    "            words = list(possible_next_words.keys())\n",
    "            weights = list(possible_next_words.values())\n",
    "\n",
    "            if words:  # If we have options\n",
    "                next_word = random.choices(words, weights=weights)[0]\n",
    "                generated_words.append(next_word)\n",
    "                current_word = next_word\n",
    "                print(\n",
    "                    f\"   Step {step + 1}: '{current_word}' (based on learned patterns)\")\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            print(\n",
    "                f\"   Step {step + 1}: No pattern found for '{current_word}', stopping\")\n",
    "            break\n",
    "\n",
    "    generated_text = ' '.join(generated_words)\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "# Execute generation phase\n",
    "generated_sentence = generation_phase_simulation(\n",
    "    learned_patterns, \"the\", max_length=6)\n",
    "\n",
    "print(f\"\\n🎉 Generated Text: '{generated_sentence}'\")\n",
    "print(\"\\n💡 Key insight: Generation applies learned patterns to create new content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4249bd0d",
   "metadata": {},
   "source": [
    "## 🔄 Complete Two-Phase Process\n",
    "\n",
    "Let's see both phases working together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e2a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_complete_process():\n",
    "    \"\"\"\n",
    "    Shows the complete GenAI process: Training → Generation\n",
    "    \"\"\"\n",
    "    print(\"🔄 COMPLETE GENERATIVE AI PROCESS\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    print(\"\\n📚 PHASE 1: TRAINING (Learning from data)\")\n",
    "    print(\"   • Input: Large amounts of text data\")\n",
    "    print(\"   • Process: Find patterns, relationships, structures\")\n",
    "    print(\"   • Output: Internal knowledge representation\")\n",
    "    print(\"   • Happens: Once, during model development\")\n",
    "    print(\"   • Goal: Build understanding of language patterns\")\n",
    "\n",
    "    print(\"\\n✨ PHASE 2: GENERATION (Using learned knowledge)\")\n",
    "    print(\"   • Input: User prompt or starting text\")\n",
    "    print(\"   • Process: Apply learned patterns to create new content\")\n",
    "    print(\"   • Output: New, original text\")\n",
    "    print(\"   • Happens: Every time you use the AI\")\n",
    "    print(\"   • Goal: Create helpful, relevant content\")\n",
    "\n",
    "    print(\"\\n🎯 KEY INSIGHT:\")\n",
    "    print(\"   Training = Learning the rules\")\n",
    "    print(\"   Generation = Applying the rules creatively\")\n",
    "\n",
    "    # Generate a few more examples\n",
    "    print(\"\\n🎲 Multiple Generation Examples from Same Training:\")\n",
    "    for i in range(3):\n",
    "        new_text = generation_phase_simulation(\n",
    "            learned_patterns, \"the\", max_length=5)\n",
    "        print(f\"   Example {i+1}: '{new_text}'\")\n",
    "\n",
    "\n",
    "demonstrate_complete_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c04f6",
   "metadata": {},
   "source": [
    "## 🤔 Critical Thinking: Training vs Generation Differences\n",
    "\n",
    "Let's explore why these phases are fundamentally different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e4bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_phase_differences():\n",
    "    \"\"\"\n",
    "    Analyzes the key differences between training and generation phases.\n",
    "    \"\"\"\n",
    "    print(\"🤔 TRAINING vs GENERATION: Key Differences\")\n",
    "    print(\"=\"*55)\n",
    "\n",
    "    differences = {\n",
    "        \"Data Requirements\": {\n",
    "            \"Training\": \"Massive datasets (millions of examples)\",\n",
    "            \"Generation\": \"Single prompt or starting text\"\n",
    "        },\n",
    "        \"Computational Cost\": {\n",
    "            \"Training\": \"Extremely expensive (weeks, months)\",\n",
    "            \"Generation\": \"Relatively fast (seconds, minutes)\"\n",
    "        },\n",
    "        \"Frequency\": {\n",
    "            \"Training\": \"Done once by AI companies\",\n",
    "            \"Generation\": \"Every time you interact with AI\"\n",
    "        },\n",
    "        \"Purpose\": {\n",
    "            \"Training\": \"Learn language patterns and knowledge\",\n",
    "            \"Generation\": \"Apply knowledge to create content\"\n",
    "        },\n",
    "        \"Output\": {\n",
    "            \"Training\": \"Updated model parameters/weights\",\n",
    "            \"Generation\": \"New text, code, or content\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for aspect, phases in differences.items():\n",
    "        print(f\"\\n📊 {aspect}:\")\n",
    "        print(f\"   📚 Training: {phases['Training']}\")\n",
    "        print(f\"   ✨ Generation: {phases['Generation']}\")\n",
    "\n",
    "    print(\"\\n🎯 ANALOGY: Learning to Drive\")\n",
    "    print(\"   📚 Training = Learning traffic rules, practicing with instructor\")\n",
    "    print(\"   ✨ Generation = Actually driving to your destination\")\n",
    "\n",
    "\n",
    "analyze_phase_differences()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9a64fb",
   "metadata": {},
   "source": [
    "## 🏆 Day 2 Knowledge Check\n",
    "\n",
    "Test your understanding of the two-phase process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def day2_knowledge_check():\n",
    "    \"\"\"\n",
    "    Interactive knowledge check for Day 2 concepts.\n",
    "    \"\"\"\n",
    "    print(\"📋 Day 2 Knowledge Check: Training vs Generation\")\n",
    "\n",
    "    scenarios = [\n",
    "        (\"GPT-4 being trained on internet text\",\n",
    "         \"Training\", \"Learning patterns from data\"),\n",
    "        (\"ChatGPT answering your question\", \"Generation\",\n",
    "         \"Using learned patterns to create response\"),\n",
    "        (\"Model learning grammar rules from books\",\n",
    "         \"Training\", \"Building internal knowledge\"),\n",
    "        (\"AI writing a poem for you\", \"Generation\",\n",
    "         \"Applying learned patterns creatively\"),\n",
    "        (\"Model adjusting its parameters on data\", \"Training\",\n",
    "         \"Updating internal knowledge representation\")\n",
    "    ]\n",
    "\n",
    "    print(\"\\nIdentify whether each scenario is Training or Generation:\")\n",
    "\n",
    "    for i, (scenario, correct_phase, explanation) in enumerate(scenarios, 1):\n",
    "        print(f\"\\n{i}. Scenario: {scenario}\")\n",
    "        print(f\"   Phase: {correct_phase}\")\n",
    "        print(f\"   Why: {explanation}\")\n",
    "\n",
    "    print(\"\\n🎯 If you understood all phases correctly, you've mastered Day 2!\")\n",
    "    return True\n",
    "\n",
    "\n",
    "day2_knowledge_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a6c4c9",
   "metadata": {},
   "source": [
    "## 📝 Day 2 Reflection (5 minutes)\n",
    "\n",
    "Reflect on the two-phase process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2aad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📝 Day 2 Reflection Questions:\")\n",
    "print(\"\\n1. Explain the difference between training and generation in your own words:\")\n",
    "print(\"   Your answer: [Write your explanation here]\")\n",
    "\n",
    "print(\"\\n2. Why do you think training is expensive but generation is fast?\")\n",
    "print(\"   Your answer: [Write your reasoning here]\")\n",
    "\n",
    "print(\"\\n3. Think of another analogy for training vs generation:\")\n",
    "print(\"   Your answer: [Write your analogy here]\")\n",
    "\n",
    "print(\"\\n🎯 Tomorrow: We'll explore the KEY COMPONENTS that make GenAI systems work\")\n",
    "print(\"📖 Next guide: Day 3 - Key Components & Architecture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df29318b",
   "metadata": {},
   "source": [
    "## ✅ Day 2 Completion Checklist\n",
    "\n",
    "Before moving to Day 3, confirm you can:\n",
    "\n",
    "- [ ] Distinguish between training and generation phases\n",
    "- [ ] Explain why training happens once but generation happens repeatedly\n",
    "- [ ] Understand that training learns patterns, generation applies them\n",
    "- [ ] Recognize the cost/speed differences between phases\n",
    "- [ ] Give examples of each phase in action\n",
    "\n",
    "**🎉 Day 2 Complete!** Ready for [Day 3: Key Components](day03-key-components.ipynb)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f736d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Day 2: Deep Dive into Training vs Generation Phases\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def simulate_training_process():\n",
    "    \"\"\"\n",
    "    Simulates and visualizes the training process of a generative model.\n",
    "    \"\"\"\n",
    "    print(\"🏋️ Training Phase Simulation\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Simulate training loss over epochs\n",
    "    np.random.seed(42)\n",
    "    epochs = np.arange(1, 101)\n",
    "\n",
    "    # Create realistic training curve\n",
    "    base_loss = 10 * np.exp(-epochs/20) + 0.5\n",
    "    noise = np.random.normal(0, 0.1, len(epochs))\n",
    "    training_loss = base_loss + noise\n",
    "\n",
    "    # Validation loss (slightly higher, more volatile)\n",
    "    val_noise = np.random.normal(0, 0.15, len(epochs))\n",
    "    validation_loss = base_loss * 1.1 + val_noise\n",
    "\n",
    "    # Create training visualization\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, training_loss, label='Training Loss',\n",
    "             color='blue', alpha=0.8)\n",
    "    plt.plot(epochs, validation_loss,\n",
    "             label='Validation Loss', color='red', alpha=0.8)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Model Training Progress')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Show learning phases\n",
    "    plt.axvspan(1, 20, alpha=0.2, color='red', label='Fast Learning')\n",
    "    plt.axvspan(20, 60, alpha=0.2, color='yellow', label='Steady Improvement')\n",
    "    plt.axvspan(60, 100, alpha=0.2, color='green', label='Fine-tuning')\n",
    "\n",
    "    # Model capacity vs complexity\n",
    "    plt.subplot(1, 2, 2)\n",
    "    complexity = np.linspace(0, 10, 100)\n",
    "\n",
    "    # Different model sizes\n",
    "    small_model = 0.5 * complexity + 2 * np.exp(-complexity/2)\n",
    "    medium_model = 0.3 * complexity + 1.5 * np.exp(-complexity/3)\n",
    "    large_model = 0.1 * complexity + 1 * np.exp(-complexity/4)\n",
    "\n",
    "    plt.plot(complexity, small_model,\n",
    "             label='Small Model (1M params)', linewidth=2)\n",
    "    plt.plot(complexity, medium_model,\n",
    "             label='Medium Model (100M params)', linewidth=2)\n",
    "    plt.plot(complexity, large_model,\n",
    "             label='Large Model (10B params)', linewidth=2)\n",
    "\n",
    "    plt.xlabel('Task Complexity')\n",
    "    plt.ylabel('Error Rate')\n",
    "    plt.title('Model Size vs Performance')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n📊 Training Insights:\")\n",
    "    print(f\"Final Training Loss: {training_loss[-1]:.3f}\")\n",
    "    print(f\"Final Validation Loss: {validation_loss[-1]:.3f}\")\n",
    "    print(f\"Training completed over {len(epochs)} epochs\")\n",
    "\n",
    "    return {\n",
    "        'final_train_loss': training_loss[-1],\n",
    "        'final_val_loss': validation_loss[-1],\n",
    "        'epochs': len(epochs)\n",
    "    }\n",
    "\n",
    "\n",
    "# Run training simulation\n",
    "training_results = simulate_training_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c406e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_generation_process():\n",
    "    \"\"\"\n",
    "    Simulates the generation phase after training is complete.\n",
    "    \"\"\"\n",
    "    print(\"\\n🎨 Generation Phase Simulation\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Simulate text generation probabilities\n",
    "    vocabulary = ['the', 'quick', 'brown', 'fox',\n",
    "                  'jumps', 'over', 'lazy', 'dog', 'and', 'runs']\n",
    "\n",
    "    # Simulate model predictions for next word\n",
    "    def generate_next_word_probabilities(context):\n",
    "        \"\"\"Simulate model's probability distribution for next word.\"\"\"\n",
    "        np.random.seed(hash(context) % 1000)  # Deterministic based on context\n",
    "        # Somewhat uniform but varied\n",
    "        probs = np.random.dirichlet(np.ones(len(vocabulary)) * 2)\n",
    "        return dict(zip(vocabulary, probs))\n",
    "\n",
    "    # Example generation scenarios\n",
    "    contexts = [\n",
    "        \"The quick\",\n",
    "        \"The fox jumps\",\n",
    "        \"Over the lazy\"\n",
    "    ]\n",
    "\n",
    "    print(\"🔮 Generation Examples:\")\n",
    "    for context in contexts:\n",
    "        print(f\"\\nContext: '{context}'\")\n",
    "        probs = generate_next_word_probabilities(context)\n",
    "\n",
    "        # Sort by probability\n",
    "        sorted_probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        print(\"Top 3 predictions:\")\n",
    "        for i, (word, prob) in enumerate(sorted_probs[:3], 1):\n",
    "            print(f\"   {i}. '{word}' ({prob:.3f} or {prob*100:.1f}%)\")\n",
    "\n",
    "        # Show generation strategies\n",
    "        print(\"\\nGeneration Strategies:\")\n",
    "\n",
    "        # Greedy (always pick highest probability)\n",
    "        greedy_word = sorted_probs[0][0]\n",
    "        print(f\"   🎯 Greedy: '{greedy_word}' (most likely)\")\n",
    "\n",
    "        # Random sampling\n",
    "        words = list(probs.keys())\n",
    "        probabilities = list(probs.values())\n",
    "        random_word = np.random.choice(words, p=probabilities)\n",
    "        print(f\"   🎲 Random: '{random_word}' (sampled)\")\n",
    "\n",
    "        # Top-k sampling (k=3)\n",
    "        top_3_words = [word for word, _ in sorted_probs[:3]]\n",
    "        top_3_probs = [prob for _, prob in sorted_probs[:3]]\n",
    "        top_3_probs = np.array(top_3_probs) / sum(top_3_probs)  # Renormalize\n",
    "        topk_word = np.random.choice(top_3_words, p=top_3_probs)\n",
    "        print(f\"   🔝 Top-k: '{topk_word}' (from top 3)\")\n",
    "\n",
    "    return vocabulary, contexts\n",
    "\n",
    "\n",
    "# Simulate generation\n",
    "vocab, contexts = simulate_generation_process()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
