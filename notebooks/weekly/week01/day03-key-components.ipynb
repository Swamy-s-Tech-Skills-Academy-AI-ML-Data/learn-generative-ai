{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "972aac60",
   "metadata": {},
   "source": [
    "# Day 3: Key Components & Architecture - Interactive Practice\n",
    "\n",
    "**Learning Objective**: Understand the essential building blocks of generative AI systems and how they work together.\n",
    "\n",
    "**Time**: 15 minutes of hands-on practice\n",
    "\n",
    "**Prerequisites**: Read [Day 3 Guide](../../../docs/daily-guides/week01/day03-key-components.md) first (10 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a7a9f",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Today's Focus: GenAI System Components\n",
    "\n",
    "Let's explore and simulate the key components that make generative AI work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b2568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import libraries for component exploration\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"ðŸš€ Day 3 Environment Ready!\")\n",
    "print(\"Today we'll explore: Key Components of GenAI Systems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522ecc18",
   "metadata": {},
   "source": [
    "## ðŸ§© Component 1: Tokenizer (Text Processing)\n",
    "\n",
    "The tokenizer breaks text into manageable pieces for the AI to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced0d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer_demo(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Simulates a simple tokenizer: converts text into tokens.\n",
    "    Real tokenizers are much more sophisticated.\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ”¤ TOKENIZER: Processing '{text}'\")\n",
    "\n",
    "    # Simple word-based tokenization (real AI uses subword tokens)\n",
    "    tokens = text.lower().replace('.', '').replace(',', '').split()\n",
    "\n",
    "    print(f\"   ðŸ“ Original text: '{text}'\")\n",
    "    print(f\"   ðŸ”¤ Tokens: {tokens}\")\n",
    "    print(f\"   ðŸ“Š Token count: {len(tokens)}\")\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Test tokenization\n",
    "sample_text = \"Hello, AI world!\"\n",
    "tokens = simple_tokenizer_demo(sample_text)\n",
    "\n",
    "print(\"\\nðŸ’¡ Key insight: Tokenizer converts human text into AI-readable format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521623d7",
   "metadata": {},
   "source": [
    "## ðŸ§  Component 2: Neural Network (Pattern Processing)\n",
    "\n",
    "The neural network processes tokens and generates predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_neural_network_demo(tokens: List[str]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Simulates a simple neural network: processes tokens and predicts next words.\n",
    "    Real neural networks have millions/billions of parameters.\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ§  NEURAL NETWORK: Processing {len(tokens)} tokens\")\n",
    "\n",
    "    # Simulate network processing with simple rules\n",
    "    word_associations = {\n",
    "        'hello': ['world', 'there', 'friend'],\n",
    "        'ai': ['model', 'system', 'technology'],\n",
    "        'world': ['peace', 'wide', 'map'],\n",
    "        'good': ['morning', 'day', 'night']\n",
    "    }\n",
    "\n",
    "    # Generate predictions for next word\n",
    "    predictions = {}\n",
    "\n",
    "    if tokens:\n",
    "        last_token = tokens[-1]\n",
    "        possible_words = word_associations.get(\n",
    "            last_token, ['the', 'and', 'is'])\n",
    "\n",
    "        # Assign random probabilities (real AI computes these)\n",
    "        for word in possible_words:\n",
    "            predictions[word] = round(random.uniform(0.1, 0.9), 3)\n",
    "\n",
    "    print(f\"   ðŸ” Analyzing tokens: {tokens}\")\n",
    "    print(f\"   ðŸŽ¯ Predictions for next word:\")\n",
    "    for word, probability in predictions.items():\n",
    "        print(f\"      '{word}': {probability} probability\")\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Test neural network component\n",
    "predictions = simple_neural_network_demo(tokens)\n",
    "\n",
    "print(\"\\nðŸ’¡ Key insight: Neural network predicts what should come next\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddbdf95",
   "metadata": {},
   "source": [
    "## ðŸŽ² Component 3: Sampling Strategy (Choice Making)\n",
    "\n",
    "The sampling strategy decides which prediction to actually use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad081394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_strategy_demo(predictions: Dict[str, float]) -> str:\n",
    "    \"\"\"\n",
    "    Simulates different sampling strategies for choosing next words.\n",
    "    This affects creativity vs predictability.\n",
    "    \"\"\"\n",
    "    print(\"ðŸŽ² SAMPLING STRATEGY: Choosing from predictions\")\n",
    "\n",
    "    if not predictions:\n",
    "        return \"the\"\n",
    "\n",
    "    print(f\"   ðŸ“Š Available predictions: {predictions}\")\n",
    "\n",
    "    # Strategy 1: Greedy (always pick highest probability)\n",
    "    greedy_choice = max(predictions.items(), key=lambda x: x[1])\n",
    "    print(\n",
    "        f\"   ðŸŽ¯ Greedy choice: '{greedy_choice[0]}' (highest probability: {greedy_choice[1]})\")\n",
    "\n",
    "    # Strategy 2: Random (weighted by probability)\n",
    "    words = list(predictions.keys())\n",
    "    weights = list(predictions.values())\n",
    "    random_choice = random.choices(words, weights=weights)[0]\n",
    "    print(f\"   ðŸŽ² Random choice: '{random_choice}' (probability-weighted)\")\n",
    "\n",
    "    # Strategy 3: Top-k (pick from top 2 choices)\n",
    "    sorted_predictions = sorted(\n",
    "        predictions.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_k_choice = random.choice(sorted_predictions[:2])[0]\n",
    "    print(f\"   ðŸ” Top-k choice: '{top_k_choice}' (from top 2 options)\")\n",
    "\n",
    "    print(\"\\nðŸ’¡ Different strategies create different styles:\")\n",
    "    print(\"      Greedy â†’ More predictable, safer\")\n",
    "    print(\"      Random â†’ More creative, varied\")\n",
    "    print(\"      Top-k â†’ Balanced creativity\")\n",
    "\n",
    "    return greedy_choice[0]  # Return greedy choice for demo\n",
    "\n",
    "\n",
    "# Test sampling strategies\n",
    "chosen_word = sampling_strategy_demo(predictions)\n",
    "\n",
    "print(f\"\\nâœ¨ Final choice: '{chosen_word}'\")\n",
    "print(\"ðŸ’¡ Key insight: Sampling strategy controls creativity vs predictability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2299e1",
   "metadata": {},
   "source": [
    "## ðŸ”„ Component Integration: Complete System\n",
    "\n",
    "Let's see how all components work together in a complete generation cycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116f239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_genai_system_demo(input_text: str, num_words: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Demonstrates all components working together in a complete GenAI system.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”„ COMPLETE GENAI SYSTEM: All Components Working Together\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    result_text = input_text\n",
    "\n",
    "    for step in range(num_words):\n",
    "        print(f\"\\nðŸ”„ Generation Step {step + 1}:\")\n",
    "        print(f\"   Current text: '{result_text}'\")\n",
    "\n",
    "        # Step 1: Tokenization\n",
    "        tokens = simple_tokenizer_demo(result_text)\n",
    "\n",
    "        # Step 2: Neural Network Processing\n",
    "        predictions = simple_neural_network_demo(tokens)\n",
    "\n",
    "        # Step 3: Sampling Strategy\n",
    "        next_word = sampling_strategy_demo(predictions)\n",
    "\n",
    "        # Step 4: Add to result\n",
    "        result_text += \" \" + next_word\n",
    "        print(f\"   âž• Added: '{next_word}'\")\n",
    "        print(f\"   ðŸ“ Updated text: '{result_text}'\")\n",
    "\n",
    "    return result_text\n",
    "\n",
    "\n",
    "# Run complete system\n",
    "final_text = complete_genai_system_demo(\"Hello AI\", 3)\n",
    "\n",
    "print(f\"\\nðŸŽ‰ FINAL GENERATED TEXT: '{final_text}'\")\n",
    "print(\"\\nðŸ’¡ This shows how all components collaborate to generate text!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dbee82",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Architecture Overview: System Design\n",
    "\n",
    "Let's visualize how components fit into the overall architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c61d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_genai_architecture():\n",
    "    \"\"\"\n",
    "    Shows the complete GenAI system architecture and data flow.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ—ï¸ GENERATIVE AI SYSTEM ARCHITECTURE\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    print(\"\\nðŸ“¥ INPUT LAYER:\")\n",
    "    print(\"   â””â”€â”€ User Prompt: 'Write a story about...'\")\n",
    "    print(\"       â””â”€â”€ ðŸ”¤ Tokenizer: Converts text â†’ tokens\")\n",
    "\n",
    "    print(\"\\nðŸ§  PROCESSING LAYER:\")\n",
    "    print(\"   â””â”€â”€ ðŸ§  Neural Network (Transformer):\")\n",
    "    print(\"       â”œâ”€â”€ Attention Mechanisms (focus on relevant parts)\")\n",
    "    print(\"       â”œâ”€â”€ Feed-forward Networks (process information)\")\n",
    "    print(\"       â””â”€â”€ Layer Normalization (stabilize learning)\")\n",
    "\n",
    "    print(\"\\nðŸŽ¯ PREDICTION LAYER:\")\n",
    "    print(\"   â””â”€â”€ ðŸ“Š Probability Distribution over vocabulary\")\n",
    "    print(\"       â””â”€â”€ Next word predictions with confidence scores\")\n",
    "\n",
    "    print(\"\\nðŸŽ² SELECTION LAYER:\")\n",
    "    print(\"   â””â”€â”€ ðŸŽ² Sampling Strategy:\")\n",
    "    print(\"       â”œâ”€â”€ Temperature (creativity control)\")\n",
    "    print(\"       â”œâ”€â”€ Top-k (limit choices)\")\n",
    "    print(\"       â””â”€â”€ Top-p (nucleus sampling)\")\n",
    "\n",
    "    print(\"\\nðŸ“¤ OUTPUT LAYER:\")\n",
    "    print(\"   â””â”€â”€ ðŸ”¤ Detokenizer: Tokens â†’ human-readable text\")\n",
    "    print(\"       â””â”€â”€ Final Response: Generated content\")\n",
    "\n",
    "    print(\"\\nðŸ”„ FEEDBACK LOOP:\")\n",
    "    print(\"   â””â”€â”€ Generated token becomes input for next prediction\")\n",
    "    print(\"       â””â”€â”€ Continues until stop condition (end token, max length)\")\n",
    "\n",
    "    print(\"\\nðŸŽ¯ KEY DESIGN PRINCIPLES:\")\n",
    "    print(\"   â€¢ Autoregressive: Each token depends on previous tokens\")\n",
    "    print(\"   â€¢ Probabilistic: Multiple possible continuations\")\n",
    "    print(\"   â€¢ Contextual: Considers full input context\")\n",
    "    print(\"   â€¢ Scalable: Works with various input lengths\")\n",
    "\n",
    "\n",
    "visualize_genai_architecture()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac7b642",
   "metadata": {},
   "source": [
    "## ðŸ† Day 3 Knowledge Check\n",
    "\n",
    "Test your understanding of GenAI components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746994ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def day3_knowledge_check():\n",
    "    \"\"\"\n",
    "    Interactive knowledge check for Day 3 components.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ“‹ Day 3 Knowledge Check: GenAI Components\")\n",
    "\n",
    "    components_quiz = [\n",
    "        (\"Converts 'Hello world' into ['hello', 'world']\",\n",
    "         \"Tokenizer\", \"Breaks text into processable pieces\"),\n",
    "        (\"Predicts next word probabilities\",\n",
    "         \"Neural Network\", \"Core processing engine\"),\n",
    "        (\"Chooses 'amazing' from ['good', 'great', 'amazing']\",\n",
    "         \"Sampling Strategy\", \"Decides which prediction to use\"),\n",
    "        (\"Maintains context across multiple words\", \"Architecture\",\n",
    "         \"Overall system design enables coherence\"),\n",
    "        (\"Controls creativity vs predictability\",\n",
    "         \"Sampling Strategy\", \"Temperature and top-k parameters\")\n",
    "    ]\n",
    "\n",
    "    print(\"\\nMatch each function to its component:\")\n",
    "\n",
    "    for i, (function, component, explanation) in enumerate(components_quiz, 1):\n",
    "        print(f\"\\n{i}. Function: {function}\")\n",
    "        print(f\"   Component: {component}\")\n",
    "        print(f\"   Why: {explanation}\")\n",
    "\n",
    "    print(\"\\nðŸŽ¯ If you can explain each component's role, you've mastered Day 3!\")\n",
    "    return True\n",
    "\n",
    "\n",
    "day3_knowledge_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd952b",
   "metadata": {},
   "source": [
    "## ðŸ“ Day 3 Reflection (5 minutes)\n",
    "\n",
    "Reflect on the system components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c267b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“ Day 3 Reflection Questions:\")\n",
    "print(\"\\n1. Which component do you think is most important and why?\")\n",
    "print(\"   Your answer: [Write your choice and reasoning here]\")\n",
    "\n",
    "print(\"\\n2. How does changing sampling strategy affect the AI's personality?\")\n",
    "print(\"   Your answer: [Write your insights here]\")\n",
    "\n",
    "print(\"\\n3. What would happen if one component failed?\")\n",
    "print(\"   Your answer: [Write your analysis here]\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Tomorrow: We'll explore the MATHEMATICAL FOUNDATIONS (probability basics)\")\n",
    "print(\"ðŸ“– Next guide: Day 4 - Probability Basics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9203fc2c",
   "metadata": {},
   "source": [
    "## âœ… Day 3 Completion Checklist\n",
    "\n",
    "Before moving to Day 4, confirm you can:\n",
    "\n",
    "- [ ] Identify the key components of GenAI systems\n",
    "- [ ] Explain what each component does\n",
    "- [ ] Understand how components work together\n",
    "- [ ] Recognize the role of sampling strategies\n",
    "- [ ] Describe the overall system architecture\n",
    "\n",
    "**ðŸŽ‰ Day 3 Complete!** Ready for [Day 4: Probability Basics](day04-probability-basics.ipynb)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be612d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Day 3: AI System Architecture Deep Dive\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def explore_system_architecture():\n",
    "    \"\"\"\n",
    "    Interactive exploration of AI system components and their relationships.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ—ï¸ AI System Architecture Explorer\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Define system components\n",
    "    components = {\n",
    "        'Input Processing': {\n",
    "            'description': 'Converts raw input into model-readable format',\n",
    "            'examples': ['Tokenization', 'Image preprocessing', 'Audio encoding'],\n",
    "            'complexity': 2,\n",
    "            'importance': 9\n",
    "        },\n",
    "        'Model Core': {\n",
    "            'description': 'The main neural network that processes information',\n",
    "            'examples': ['Transformer', 'CNN', 'RNN'],\n",
    "            'complexity': 10,\n",
    "            'importance': 10\n",
    "        },\n",
    "        'Memory Systems': {\n",
    "            'description': 'Stores and retrieves information during processing',\n",
    "            'examples': ['Attention weights', 'Hidden states', 'External memory'],\n",
    "            'complexity': 7,\n",
    "            'importance': 8\n",
    "        },\n",
    "        'Output Generation': {\n",
    "            'description': 'Converts model outputs into human-readable results',\n",
    "            'examples': ['Text decoding', 'Image synthesis', 'Audio generation'],\n",
    "            'complexity': 6,\n",
    "            'importance': 9\n",
    "        },\n",
    "        'Training Infrastructure': {\n",
    "            'description': 'Systems that enable model learning and optimization',\n",
    "            'examples': ['Loss computation', 'Gradient updates', 'Data pipelines'],\n",
    "            'complexity': 8,\n",
    "            'importance': 7\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create architecture visualization\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    # Component complexity vs importance\n",
    "    names = list(components.keys())\n",
    "    complexity = [components[name]['complexity'] for name in names]\n",
    "    importance = [components[name]['importance'] for name in names]\n",
    "\n",
    "    scatter = ax1.scatter(complexity, importance, s=200,\n",
    "                          alpha=0.7, c=range(len(names)), cmap='viridis')\n",
    "\n",
    "    for i, name in enumerate(names):\n",
    "        ax1.annotate(name, (complexity[i], importance[i]),\n",
    "                     xytext=(5, 5), textcoords='offset points',\n",
    "                     fontsize=9, ha='left')\n",
    "\n",
    "    ax1.set_xlabel('Complexity (1-10)')\n",
    "    ax1.set_ylabel('Importance (1-10)')\n",
    "    ax1.set_title('System Components: Complexity vs Importance')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Data flow simulation\n",
    "    flow_stages = ['Raw Input', 'Preprocessed',\n",
    "                   'Encoded', 'Processed', 'Decoded', 'Final Output']\n",
    "    data_sizes = [1000, 800, 512, 256, 512, 100]  # Simulated data sizes\n",
    "\n",
    "    ax2.plot(flow_stages, data_sizes, 'o-',\n",
    "             linewidth=3, markersize=8, color='blue')\n",
    "    ax2.fill_between(range(len(flow_stages)),\n",
    "                     data_sizes, alpha=0.3, color='blue')\n",
    "    ax2.set_ylabel('Data Size (relative)')\n",
    "    ax2.set_title('Data Flow Through System')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # Component interaction heatmap\n",
    "    interaction_matrix = np.array([\n",
    "        [1.0, 0.9, 0.3, 0.2, 0.8],  # Input Processing\n",
    "        [0.9, 1.0, 0.9, 0.8, 0.9],  # Model Core\n",
    "        [0.3, 0.9, 1.0, 0.4, 0.5],  # Memory Systems\n",
    "        [0.2, 0.8, 0.4, 1.0, 0.3],  # Output Generation\n",
    "        [0.8, 0.9, 0.5, 0.3, 1.0]   # Training Infrastructure\n",
    "    ])\n",
    "\n",
    "    im = ax3.imshow(interaction_matrix, cmap='YlOrRd', aspect='auto')\n",
    "    ax3.set_xticks(range(len(names)))\n",
    "    ax3.set_yticks(range(len(names)))\n",
    "    ax3.set_xticklabels([name[:10] + '...' if len(name) >\n",
    "                        10 else name for name in names], rotation=45, ha='right')\n",
    "    ax3.set_yticklabels([name[:10] + '...' if len(name) >\n",
    "                        10 else name for name in names])\n",
    "    ax3.set_title('Component Interaction Strength')\n",
    "\n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax3, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Interaction Strength')\n",
    "\n",
    "    # Performance over time\n",
    "    time_steps = np.arange(0, 100, 5)\n",
    "    processing_time = 50 + 30 * \\\n",
    "        np.sin(time_steps / 10) + np.random.normal(0, 5, len(time_steps))\n",
    "    memory_usage = 70 + 20 * \\\n",
    "        np.cos(time_steps / 15) + np.random.normal(0, 3, len(time_steps))\n",
    "\n",
    "    ax4_twin = ax4.twinx()\n",
    "\n",
    "    line1 = ax4.plot(time_steps, processing_time, 'b-',\n",
    "                     label='Processing Time', linewidth=2)\n",
    "    line2 = ax4_twin.plot(time_steps, memory_usage, 'r-',\n",
    "                          label='Memory Usage', linewidth=2)\n",
    "\n",
    "    ax4.set_xlabel('Time Steps')\n",
    "    ax4.set_ylabel('Processing Time (ms)', color='blue')\n",
    "    ax4_twin.set_ylabel('Memory Usage (%)', color='red')\n",
    "    ax4.set_title('System Performance Over Time')\n",
    "\n",
    "    # Combine legends\n",
    "    lines = line1 + line2\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax4.legend(lines, labels, loc='upper right')\n",
    "\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return components\n",
    "\n",
    "\n",
    "# Explore the architecture\n",
    "architecture_data = explore_system_architecture()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
