{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "972aac60",
   "metadata": {},
   "source": [
    "# Day 3: Key Components & Architecture - Interactive Practice\n",
    "\n",
    "**Learning Objective**: Understand the essential building blocks of generative AI systems and how they work together.\n",
    "\n",
    "**Time**: 15 minutes of hands-on practice\n",
    "\n",
    "**Prerequisites**: Read [Day 3 Guide](../../../docs/daily-guides/week01/day03-key-components.md) first (10 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a7a9f",
   "metadata": {},
   "source": [
    "## ğŸ¯ Today's Focus: GenAI System Components\n",
    "\n",
    "Let's explore and simulate the key components that make generative AI work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b2568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import libraries for component exploration\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"ğŸš€ Day 3 Environment Ready!\")\n",
    "print(\"Today we'll explore: Key Components of GenAI Systems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522ecc18",
   "metadata": {},
   "source": [
    "## ğŸ§© Component 1: Tokenizer (Text Processing)\n",
    "\n",
    "The tokenizer breaks text into manageable pieces for the AI to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced0d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer_demo(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Simulates a simple tokenizer: converts text into tokens.\n",
    "    Real tokenizers are much more sophisticated.\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ”¤ TOKENIZER: Processing '{text}'\")\n",
    "\n",
    "    # Simple word-based tokenization (real AI uses subword tokens)\n",
    "    tokens = text.lower().replace('.', '').replace(',', '').split()\n",
    "\n",
    "    print(f\"   ğŸ“ Original text: '{text}'\")\n",
    "    print(f\"   ğŸ”¤ Tokens: {tokens}\")\n",
    "    print(f\"   ğŸ“Š Token count: {len(tokens)}\")\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Test tokenization\n",
    "sample_text = \"Hello, AI world!\"\n",
    "tokens = simple_tokenizer_demo(sample_text)\n",
    "\n",
    "print(\"\\nğŸ’¡ Key insight: Tokenizer converts human text into AI-readable format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521623d7",
   "metadata": {},
   "source": [
    "## ğŸ§  Component 2: Neural Network (Pattern Processing)\n",
    "\n",
    "The neural network processes tokens and generates predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_neural_network_demo(tokens: List[str]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Simulates a simple neural network: processes tokens and predicts next words.\n",
    "    Real neural networks have millions/billions of parameters.\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ§  NEURAL NETWORK: Processing {len(tokens)} tokens\")\n",
    "\n",
    "    # Simulate network processing with simple rules\n",
    "    word_associations = {\n",
    "        'hello': ['world', 'there', 'friend'],\n",
    "        'ai': ['model', 'system', 'technology'],\n",
    "        'world': ['peace', 'wide', 'map'],\n",
    "        'good': ['morning', 'day', 'night']\n",
    "    }\n",
    "\n",
    "    # Generate predictions for next word\n",
    "    predictions = {}\n",
    "\n",
    "    if tokens:\n",
    "        last_token = tokens[-1]\n",
    "        possible_words = word_associations.get(\n",
    "            last_token, ['the', 'and', 'is'])\n",
    "\n",
    "        # Assign random probabilities (real AI computes these)\n",
    "        for word in possible_words:\n",
    "            predictions[word] = round(random.uniform(0.1, 0.9), 3)\n",
    "\n",
    "    print(f\"   ğŸ” Analyzing tokens: {tokens}\")\n",
    "    print(f\"   ğŸ¯ Predictions for next word:\")\n",
    "    for word, probability in predictions.items():\n",
    "        print(f\"      '{word}': {probability} probability\")\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Test neural network component\n",
    "predictions = simple_neural_network_demo(tokens)\n",
    "\n",
    "print(\"\\nğŸ’¡ Key insight: Neural network predicts what should come next\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddbdf95",
   "metadata": {},
   "source": [
    "## ğŸ² Component 3: Sampling Strategy (Choice Making)\n",
    "\n",
    "The sampling strategy decides which prediction to actually use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad081394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_strategy_demo(predictions: Dict[str, float]) -> str:\n",
    "    \"\"\"\n",
    "    Simulates different sampling strategies for choosing next words.\n",
    "    This affects creativity vs predictability.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ² SAMPLING STRATEGY: Choosing from predictions\")\n",
    "\n",
    "    if not predictions:\n",
    "        return \"the\"\n",
    "\n",
    "    print(f\"   ğŸ“Š Available predictions: {predictions}\")\n",
    "\n",
    "    # Strategy 1: Greedy (always pick highest probability)\n",
    "    greedy_choice = max(predictions.items(), key=lambda x: x[1])\n",
    "    print(\n",
    "        f\"   ğŸ¯ Greedy choice: '{greedy_choice[0]}' (highest probability: {greedy_choice[1]})\")\n",
    "\n",
    "    # Strategy 2: Random (weighted by probability)\n",
    "    words = list(predictions.keys())\n",
    "    weights = list(predictions.values())\n",
    "    random_choice = random.choices(words, weights=weights)[0]\n",
    "    print(f\"   ğŸ² Random choice: '{random_choice}' (probability-weighted)\")\n",
    "\n",
    "    # Strategy 3: Top-k (pick from top 2 choices)\n",
    "    sorted_predictions = sorted(\n",
    "        predictions.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_k_choice = random.choice(sorted_predictions[:2])[0]\n",
    "    print(f\"   ğŸ” Top-k choice: '{top_k_choice}' (from top 2 options)\")\n",
    "\n",
    "    print(\"\\nğŸ’¡ Different strategies create different styles:\")\n",
    "    print(\"      Greedy â†’ More predictable, safer\")\n",
    "    print(\"      Random â†’ More creative, varied\")\n",
    "    print(\"      Top-k â†’ Balanced creativity\")\n",
    "\n",
    "    return greedy_choice[0]  # Return greedy choice for demo\n",
    "\n",
    "\n",
    "# Test sampling strategies\n",
    "chosen_word = sampling_strategy_demo(predictions)\n",
    "\n",
    "print(f\"\\nâœ¨ Final choice: '{chosen_word}'\")\n",
    "print(\"ğŸ’¡ Key insight: Sampling strategy controls creativity vs predictability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2299e1",
   "metadata": {},
   "source": [
    "## ğŸ”„ Component Integration: Complete System\n",
    "\n",
    "Let's see how all components work together in a complete generation cycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116f239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_genai_system_demo(input_text: str, num_words: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Demonstrates all components working together in a complete GenAI system.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”„ COMPLETE GENAI SYSTEM: All Components Working Together\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    result_text = input_text\n",
    "\n",
    "    for step in range(num_words):\n",
    "        print(f\"\\nğŸ”„ Generation Step {step + 1}:\")\n",
    "        print(f\"   Current text: '{result_text}'\")\n",
    "\n",
    "        # Step 1: Tokenization\n",
    "        tokens = simple_tokenizer_demo(result_text)\n",
    "\n",
    "        # Step 2: Neural Network Processing\n",
    "        predictions = simple_neural_network_demo(tokens)\n",
    "\n",
    "        # Step 3: Sampling Strategy\n",
    "        next_word = sampling_strategy_demo(predictions)\n",
    "\n",
    "        # Step 4: Add to result\n",
    "        result_text += \" \" + next_word\n",
    "        print(f\"   â• Added: '{next_word}'\")\n",
    "        print(f\"   ğŸ“ Updated text: '{result_text}'\")\n",
    "\n",
    "    return result_text\n",
    "\n",
    "\n",
    "# Run complete system\n",
    "final_text = complete_genai_system_demo(\"Hello AI\", 3)\n",
    "\n",
    "print(f\"\\nğŸ‰ FINAL GENERATED TEXT: '{final_text}'\")\n",
    "print(\"\\nğŸ’¡ This shows how all components collaborate to generate text!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dbee82",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ Architecture Overview: System Design\n",
    "\n",
    "Let's visualize how components fit into the overall architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c61d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_genai_architecture():\n",
    "    \"\"\"\n",
    "    Shows the complete GenAI system architecture and data flow.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ—ï¸ GENERATIVE AI SYSTEM ARCHITECTURE\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    print(\"\\nğŸ“¥ INPUT LAYER:\")\n",
    "    print(\"   â””â”€â”€ User Prompt: 'Write a story about...'\")\n",
    "    print(\"       â””â”€â”€ ğŸ”¤ Tokenizer: Converts text â†’ tokens\")\n",
    "\n",
    "    print(\"\\nğŸ§  PROCESSING LAYER:\")\n",
    "    print(\"   â””â”€â”€ ğŸ§  Neural Network (Transformer):\")\n",
    "    print(\"       â”œâ”€â”€ Attention Mechanisms (focus on relevant parts)\")\n",
    "    print(\"       â”œâ”€â”€ Feed-forward Networks (process information)\")\n",
    "    print(\"       â””â”€â”€ Layer Normalization (stabilize learning)\")\n",
    "\n",
    "    print(\"\\nğŸ¯ PREDICTION LAYER:\")\n",
    "    print(\"   â””â”€â”€ ğŸ“Š Probability Distribution over vocabulary\")\n",
    "    print(\"       â””â”€â”€ Next word predictions with confidence scores\")\n",
    "\n",
    "    print(\"\\nğŸ² SELECTION LAYER:\")\n",
    "    print(\"   â””â”€â”€ ğŸ² Sampling Strategy:\")\n",
    "    print(\"       â”œâ”€â”€ Temperature (creativity control)\")\n",
    "    print(\"       â”œâ”€â”€ Top-k (limit choices)\")\n",
    "    print(\"       â””â”€â”€ Top-p (nucleus sampling)\")\n",
    "\n",
    "    print(\"\\nğŸ“¤ OUTPUT LAYER:\")\n",
    "    print(\"   â””â”€â”€ ğŸ”¤ Detokenizer: Tokens â†’ human-readable text\")\n",
    "    print(\"       â””â”€â”€ Final Response: Generated content\")\n",
    "\n",
    "    print(\"\\nğŸ”„ FEEDBACK LOOP:\")\n",
    "    print(\"   â””â”€â”€ Generated token becomes input for next prediction\")\n",
    "    print(\"       â””â”€â”€ Continues until stop condition (end token, max length)\")\n",
    "\n",
    "    print(\"\\nğŸ¯ KEY DESIGN PRINCIPLES:\")\n",
    "    print(\"   â€¢ Autoregressive: Each token depends on previous tokens\")\n",
    "    print(\"   â€¢ Probabilistic: Multiple possible continuations\")\n",
    "    print(\"   â€¢ Contextual: Considers full input context\")\n",
    "    print(\"   â€¢ Scalable: Works with various input lengths\")\n",
    "\n",
    "\n",
    "visualize_genai_architecture()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac7b642",
   "metadata": {},
   "source": [
    "## ğŸ† Day 3 Knowledge Check\n",
    "\n",
    "Test your understanding of GenAI components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746994ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def day3_knowledge_check():\n",
    "    \"\"\"\n",
    "    Interactive knowledge check for Day 3 components.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“‹ Day 3 Knowledge Check: GenAI Components\")\n",
    "\n",
    "    components_quiz = [\n",
    "        (\"Converts 'Hello world' into ['hello', 'world']\",\n",
    "         \"Tokenizer\", \"Breaks text into processable pieces\"),\n",
    "        (\"Predicts next word probabilities\",\n",
    "         \"Neural Network\", \"Core processing engine\"),\n",
    "        (\"Chooses 'amazing' from ['good', 'great', 'amazing']\",\n",
    "         \"Sampling Strategy\", \"Decides which prediction to use\"),\n",
    "        (\"Maintains context across multiple words\", \"Architecture\",\n",
    "         \"Overall system design enables coherence\"),\n",
    "        (\"Controls creativity vs predictability\",\n",
    "         \"Sampling Strategy\", \"Temperature and top-k parameters\")\n",
    "    ]\n",
    "\n",
    "    print(\"\\nMatch each function to its component:\")\n",
    "\n",
    "    for i, (function, component, explanation) in enumerate(components_quiz, 1):\n",
    "        print(f\"\\n{i}. Function: {function}\")\n",
    "        print(f\"   Component: {component}\")\n",
    "        print(f\"   Why: {explanation}\")\n",
    "\n",
    "    print(\"\\nğŸ¯ If you can explain each component's role, you've mastered Day 3!\")\n",
    "    return True\n",
    "\n",
    "\n",
    "day3_knowledge_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd952b",
   "metadata": {},
   "source": [
    "## ğŸ“ Day 3 Reflection (5 minutes)\n",
    "\n",
    "Reflect on the system components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c267b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“ Day 3 Reflection Questions:\")\n",
    "print(\"\\n1. Which component do you think is most important and why?\")\n",
    "print(\"   Your answer: [Write your choice and reasoning here]\")\n",
    "\n",
    "print(\"\\n2. How does changing sampling strategy affect the AI's personality?\")\n",
    "print(\"   Your answer: [Write your insights here]\")\n",
    "\n",
    "print(\"\\n3. What would happen if one component failed?\")\n",
    "print(\"   Your answer: [Write your analysis here]\")\n",
    "\n",
    "print(\"\\nğŸ¯ Tomorrow: We'll explore the MATHEMATICAL FOUNDATIONS (probability basics)\")\n",
    "print(\"ğŸ“– Next guide: Day 4 - Probability Basics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9203fc2c",
   "metadata": {},
   "source": [
    "## âœ… Day 3 Completion Checklist\n",
    "\n",
    "Before moving to Day 4, confirm you can:\n",
    "\n",
    "- [ ] Identify the key components of GenAI systems\n",
    "- [ ] Explain what each component does\n",
    "- [ ] Understand how components work together\n",
    "- [ ] Recognize the role of sampling strategies\n",
    "- [ ] Describe the overall system architecture\n",
    "\n",
    "**ğŸ‰ Day 3 Complete!** Ready for [Day 4: Probability Basics](day04-probability-basics.ipynb)?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
